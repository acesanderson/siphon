from pydantic import BaseModel, Field
from siphon.data.type_definitions.source_type import SourceType
from siphon.data.context import Context
from siphon.logs.logging_config import get_logger
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from siphon.synthetic_data.synthetic_data_classes import SyntheticDataUnion

logger = get_logger(__name__)


class SyntheticData(BaseModel):
    """
    AI-generated enrichments, applied as a "finishing step" to the content.
    """

    sourcetype: SourceType

    title: str = Field(
        default="", description="Title of the content, either extracted or generated"
    )
    description: str = Field(
        default="", description="Short description or summary of the content"
    )
    summary: str = Field(default="", description="Detailed summary of the content")
    topics: list[str] = Field(
        default_factory=list,
        description="List of topics or keywords associated with the content, an area liable to change with cluster analyses.",
    )
    entities: list[str] = Field(
        default_factory=list,
        description="List of entities (people, places, organizations) mentioned in the content.",
    )

    @classmethod
    def from_context(
        cls,
        context: Context,
        cloud: bool = False,
        model_str: str = "gemini2.5",
        server_side: bool = False,
    ) -> "SyntheticDataUnion":
        """
        Create an instance of SyntheticData from llm context, typically generated by an LLM.
        Subclasses for each SourceType may override this.
        """
        if not server_side:  # Remote by default
            return cls._from_context_remote(context, cloud, model_str)
        else:  # Direct call, e.g. server side
            return cls._from_context_direct(context, cloud, model_str)

    @classmethod
    def _from_context_direct(cls, context, cloud, model_str) -> "SyntheticDataUnion":
        """
        Directly create SyntheticData on this machine. (as opposed to the server call)
        Can be cloud or local LLMs.
        NOTE: currently hardcodes gpt-oss:latest for local generation.
        """
        if cloud:
            logger.info("Using cloud synthetic data generation")
        else:
            model_str = "gpt-oss:latest"
            logger.info("Using local synthetic data generation")

        from siphon.synthetic_data.synthetic_data_classes import (
            SyntheticDataClasses,
        )

        source_type = context.sourcetype
        for synthetic_data_class in SyntheticDataClasses:
            # Match class name to source type value
            expected_class_name = f"{source_type.value}SyntheticData"
            if synthetic_data_class.__name__ == expected_class_name:
                logger.info(
                    f"Using SyntheticData class: {synthetic_data_class.__name__}"
                )
                return synthetic_data_class.from_context(
                    context=context, model_str=model_str
                )

        raise ValueError(f"No SyntheticData class found for source type {source_type}.")

    @classmethod
    def _from_context_remote(cls, context, cloud, model_str) -> "SyntheticDataUnion":
        """
        Create SyntheticData by calling a remote service (e.g., headwater).
        Fun fact: this turns into a call of the other method (_from_context_direct) on the server side.
        """
        _ = cloud  # currently unused, as model_str contains the model choice
        logger.info("Using local synthetic data generation")
        from headwater_api.client.headwater_client import HeadwaterClient

        from headwater_api.classes import SyntheticDataRequest

        client = HeadwaterClient()
        request = SyntheticDataRequest(context=context, model=model_str)
        return client.siphon.generate_synthetic_data(request)
